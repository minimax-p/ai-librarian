{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-17T20:53:22.929474Z",
     "start_time": "2024-12-17T20:53:19.544346Z"
    }
   },
   "source": [
    "import os\n",
    "%pip install -q llama-index\n",
    "%pip install -q llama-index-llms-groq\n",
    "%pip install -q llama-index-embeddings-huggingface docx2txt\n",
    "%pip install llama-index-llms-ollama"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-index-llms-ollama in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (0.4.2)\r\n",
      "Collecting llama-index-core<0.13.0,>=0.12.0 (from llama-index-llms-ollama)\r\n",
      "  Using cached llama_index_core-0.12.5-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: ollama>=0.3.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-llms-ollama) (0.3.3)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (2.0.34)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (3.10.5)\r\n",
      "Requirement already satisfied: dataclasses-json in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (0.6.7)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (1.2.14)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (1.0.8)\r\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (1.2.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (2024.9.0)\r\n",
      "Requirement already satisfied: httpx in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (0.27.2)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (3.3)\r\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (3.9.1)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (1.26.4)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (10.4.0)\r\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (2.9.0)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (8.5.0)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (0.7.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (4.66.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (4.12.2)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (1.16.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (2.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (24.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (6.1.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (1.11.1)\r\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (4.4.0)\r\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (2024.8.30)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (1.0.5)\r\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (3.8)\r\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (0.14.0)\r\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (2024.9.11)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (2.23.2)\r\n",
      "Requirement already satisfied: tzdata in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (2024.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (2.2.3)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (3.1.1)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (1.0.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (3.22.0)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/anaconda3/envs/COS243/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-ollama) (24.1)\r\n",
      "Using cached llama_index_core-0.12.5-py3-none-any.whl (1.6 MB)\r\n",
      "Installing collected packages: llama-index-core\r\n",
      "  Attempting uninstall: llama-index-core\r\n",
      "    Found existing installation: llama-index-core 0.10.68.post1\r\n",
      "    Uninstalling llama-index-core-0.10.68.post1:\r\n",
      "      Successfully uninstalled llama-index-core-0.10.68.post1\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "llama-index-program-openai 0.1.7 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.12.5 which is incompatible.\r\n",
      "llama-index-cli 0.1.13 requires llama-index-core<0.11.0,>=0.10.11.post1, but you have llama-index-core 0.12.5 which is incompatible.\r\n",
      "llama-index-llms-openai 0.1.31 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.12.5 which is incompatible.\r\n",
      "llama-index-agent-openai 0.1.7 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.5 which is incompatible.\r\n",
      "llama-index-indices-managed-llama-cloud 0.1.6 requires llama-index-core<0.11.0,>=0.10.0, but you have llama-index-core 0.12.5 which is incompatible.\r\n",
      "llama-index-multi-modal-llms-openai 0.1.9 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.5 which is incompatible.\r\n",
      "llama-index-readers-llama-parse 0.1.6 requires llama-index-core<0.11.0,>=0.10.7, but you have llama-index-core 0.12.5 which is incompatible.\r\n",
      "llama-index-embeddings-openai 0.1.11 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.5 which is incompatible.\r\n",
      "llama-index 0.10.18 requires llama-index-core<0.11.0,>=0.10.18, but you have llama-index-core 0.12.5 which is incompatible.\r\n",
      "llama-index-readers-file 0.1.33 requires llama-index-core<0.11.0,>=0.10.37.post1, but you have llama-index-core 0.12.5 which is incompatible.\r\n",
      "llama-index-question-gen-openai 0.1.3 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.5 which is incompatible.\r\n",
      "llama-index-embeddings-huggingface 0.2.0 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.5 which is incompatible.\r\n",
      "llama-index-llms-groq 0.1.3 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.5 which is incompatible.\r\n",
      "llama-index-llms-openai-like 0.1.3 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.5 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed llama-index-core-0.12.5\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T21:09:20.176751Z",
     "start_time": "2024-12-17T21:09:20.173863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ],
   "id": "94237fcf18be93b8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T21:09:31.772014Z",
     "start_time": "2024-12-17T21:09:31.743921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    SummaryIndex\n",
    ")\n",
    "\n",
    "\n",
    "from llama_index.core.settings import Settings\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "#LLM Config\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(model=\"gpt-4o-mini\",api_key=OPENAI_API_KEY)\n",
    "\n",
    "# from llama_index.llms.openai import OpenAI\n",
    "# \n",
    "# llm = OpenAI(\n",
    "#     model=\"gpt-4o\",\n",
    "#     api_key=OPENAI_API_KEY,  # uses OPENAI_API_KEY env var by default\n",
    "# )\n",
    "\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 512\n",
    "from IPython.display import display, HTML"
   ],
   "id": "6c80a30490d05f39",
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for OpenAI\nlogprobs\n  Field required [type=missing, input_value={'model': 'gpt-4o-mini', ...: None, 'strict': False}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\ndefault_headers\n  Input should be a valid dictionary [type=dict_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.9/v/dict_type",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 17\u001B[0m\n\u001B[1;32m     13\u001B[0m OPENAI_API_KEY \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOPENAI_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mllama_index\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mllms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mopenai\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OpenAI\n\u001B[0;32m---> 17\u001B[0m llm \u001B[38;5;241m=\u001B[39m \u001B[43mOpenAI\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgpt-4o-mini\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# from llama_index.llms.openai import OpenAI\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# \u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# llm = OpenAI(\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m#     model=\"gpt-4o\",\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m#     api_key=OPENAI_API_KEY,  # uses OPENAI_API_KEY env var by default\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[1;32m     27\u001B[0m embed_model \u001B[38;5;241m=\u001B[39m HuggingFaceEmbedding(model_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBAAI/bge-small-en-v1.5\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COS243/lib/python3.11/site-packages/llama_index/llms/openai/base.py:247\u001B[0m, in \u001B[0;36mOpenAI.__init__\u001B[0;34m(self, model, temperature, max_tokens, additional_kwargs, max_retries, timeout, reuse_client, api_key, api_base, api_version, callback_manager, default_headers, http_client, async_http_client, system_prompt, messages_to_prompt, completion_to_prompt, pydantic_program_mode, output_parser, strict, **kwargs)\u001B[0m\n\u001B[1;32m    239\u001B[0m additional_kwargs \u001B[38;5;241m=\u001B[39m additional_kwargs \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[1;32m    241\u001B[0m api_key, api_base, api_version \u001B[38;5;241m=\u001B[39m resolve_openai_credentials(\n\u001B[1;32m    242\u001B[0m     api_key\u001B[38;5;241m=\u001B[39mapi_key,\n\u001B[1;32m    243\u001B[0m     api_base\u001B[38;5;241m=\u001B[39mapi_base,\n\u001B[1;32m    244\u001B[0m     api_version\u001B[38;5;241m=\u001B[39mapi_version,\n\u001B[1;32m    245\u001B[0m )\n\u001B[0;32m--> 247\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    250\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[43m    \u001B[49m\u001B[43madditional_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madditional_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallback_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mapi_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mapi_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43mapi_base\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_base\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreuse_client\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreuse_client\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdefault_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    260\u001B[0m \u001B[43m    \u001B[49m\u001B[43msystem_prompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msystem_prompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessages_to_prompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmessages_to_prompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompletion_to_prompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompletion_to_prompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpydantic_program_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpydantic_program_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_parser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_parser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    270\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aclient \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COS243/lib/python3.11/site-packages/llama_index/core/llms/function_calling.py:27\u001B[0m, in \u001B[0;36mFunctionCallingLLM.__init__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;66;03m# Help static checkers understand this class hierarchy\u001B[39;00m\n\u001B[0;32m---> 27\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COS243/lib/python3.11/site-packages/pydantic/main.py:211\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[0;34m(self, **data)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001B[39;00m\n\u001B[1;32m    210\u001B[0m __tracebackhide__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 211\u001B[0m validated_self \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__pydantic_validator__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate_python\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mself_instance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m validated_self:\n\u001B[1;32m    213\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    214\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA custom validator is returning a value other than `self`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    215\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReturning anything other than `self` from a top level model validator isn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt supported when validating via `__init__`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    216\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    217\u001B[0m         category\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    218\u001B[0m     )\n",
      "\u001B[0;31mValidationError\u001B[0m: 2 validation errors for OpenAI\nlogprobs\n  Field required [type=missing, input_value={'model': 'gpt-4o-mini', ...: None, 'strict': False}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\ndefault_headers\n  Input should be a valid dictionary [type=dict_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.9/v/dict_type"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:53:25.479053Z",
     "start_time": "2024-12-13T22:53:47.245267Z"
    }
   },
   "cell_type": "code",
   "source": "files = [file for file in os.listdir('./upload') if os.path.isfile(os.path.join('./upload', file))]",
   "id": "7d34aaee94fc6ada",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:53:25.480659Z",
     "start_time": "2024-12-13T22:53:48.211386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_docs = {}\n",
    "for file in files:\n",
    "    file_docs[file] = SimpleDirectoryReader(\n",
    "        input_files=[f\"./upload/{file}\"]\n",
    "    ).load_data()\n"
   ],
   "id": "9ee8f1d7305c417f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:53:25.480840Z",
     "start_time": "2024-12-13T22:54:08.930341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for file in files:\n",
    "    print(file)"
   ],
   "id": "290ca63ce16b270d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The-Morgan-Kaufmann-Series-in-Data-Management-Systems-Jiawei-Han-Micheline-Kamber-Jian-Pei-Data-Mining.-Concepts-and-Techniques-3rd-Edition-Morgan-Kaufmann-2011.pdf\n",
      "The Theory That Would Not Die How Bayes Rule Cracked the Enigma Code Hunted Down Russian Submarines and Emerged Triumphant from Two Centuries of Controversy by Sharon Bertsch McGrayne.pdf\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:53:25.481004Z",
     "start_time": "2024-12-13T22:54:10.136891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "# Build agents dictionary\n",
    "agents = {}\n",
    "\n",
    "for file in files:\n",
    "    # build vector index\n",
    "    vector_index = VectorStoreIndex.from_documents(\n",
    "        file_docs[file],\n",
    "    )\n",
    "    # build summary index\n",
    "    summary_index = SummaryIndex.from_documents(\n",
    "        file_docs[file],\n",
    "    )\n",
    "    # define query engines\n",
    "    vector_query_engine = vector_index.as_query_engine()\n",
    "    summary_query_engine = summary_index.as_query_engine()\n",
    "\n",
    "    # define tools\n",
    "    query_engine_tools = [\n",
    "        QueryEngineTool(\n",
    "            query_engine=vector_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"vector_tool\",\n",
    "                description=(\n",
    "                    f\"Useful for retrieving specific context from {file}\"\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "        QueryEngineTool(\n",
    "            query_engine=summary_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"summary_tool\",\n",
    "                description=(\n",
    "                    \"Useful for summarization questions related to\"\n",
    "                    f\" {file}\"\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # build agent\n",
    "    agent = ReActAgent.from_tools(\n",
    "        query_engine_tools,\n",
    "        llm=llm,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    agents[file] = agent\n"
   ],
   "id": "9f33a66881b90e65",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "46048edce379a0af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:53:25.481200Z",
     "start_time": "2024-12-10T22:42:46.626395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.schema import IndexNode\n",
    "\n",
    "# define top-level nodes\n",
    "objects = []\n",
    "for file in files:\n",
    "    # define index node that links to these agents\n",
    "    wiki_summary = (\n",
    "        f\"This content contains the full book of {file}. Use this index if you need to lookup specific facts about {file}.\"\n",
    "    )\n",
    "    node = IndexNode(\n",
    "        text=wiki_summary, index_id=file, obj=agents[file]\n",
    "    )\n",
    "    objects.append(node)\n"
   ],
   "id": "a0f46367fdb8b442",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /opt/anaconda3/envs/COS243/lib/python3.11/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# define top-level nodes\u001B[39;00m\n\u001B[1;32m      4\u001B[0m objects \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m \u001B[43mfiles\u001B[49m:\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;66;03m# define index node that links to these agents\u001B[39;00m\n\u001B[1;32m      7\u001B[0m     wiki_summary \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m      8\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis content contains the full book of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Use this index if you need to lookup specific facts about \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      9\u001B[0m     )\n\u001B[1;32m     10\u001B[0m     node \u001B[38;5;241m=\u001B[39m IndexNode(\n\u001B[1;32m     11\u001B[0m         text\u001B[38;5;241m=\u001B[39mwiki_summary, index_id\u001B[38;5;241m=\u001B[39mfile, obj\u001B[38;5;241m=\u001B[39magents[file]\n\u001B[1;32m     12\u001B[0m     )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'files' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:53:25.481327Z",
     "start_time": "2024-12-10T01:59:17.861563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vector_index = VectorStoreIndex(\n",
    "    objects=objects,\n",
    ")\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=1, verbose=True)\n"
   ],
   "id": "950e41f4d594f409",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:53:25.481445Z",
     "start_time": "2024-12-10T01:59:17.925243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper function for print\n",
    "def print_response(response):\n",
    "    display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
   ],
   "id": "88d4402f680fb7bd",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:53:25.481532Z",
     "start_time": "2024-12-10T04:50:55.060259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# should use Toronto agent -> vector tool\n",
    "response = query_engine.query( \"Provide a comprehensive overview of how Bayesian probability evolved from a theoretical concept to a critical wartime intelligence tool\")\n"
   ],
   "id": "ddb4862f05af3ea6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;3;38;2;11;159;203mRetrieval entering The Theory That Would Not Die How Bayes Rule Cracked the Enigma Code, Hunted Down Russian Submarines, and Emerged Triumphant from Two Centuries of Controversy by Sharon Bertsch McGrayne.pdf: ReActAgent\n",
      "\u001B[0m\u001B[1;3;38;2;237;90;200mRetrieving from object ReActAgent with query Provide a comprehensive overview of how Bayesian probability evolved from a theoretical concept to a critical wartime intelligence tool\n",
      "\u001B[0m> Running step 349de761-6eab-4189-8ba8-6871210a9877. Step input: Provide a comprehensive overview of how Bayesian probability evolved from a theoretical concept to a critical wartime intelligence tool\n",
      "\u001B[1;3;38;5;200mThought: The user is asking for a comprehensive overview of the evolution of Bayesian probability, particularly its transition from a theoretical concept to a critical tool in wartime intelligence. I will need to gather detailed information from the book \"The Theory That Would Not Die\" by Sharon Bertsch McGrayne to provide an accurate response.\n",
      "Action: summary_tool\n",
      "Action Input: {'input': 'Overview of the evolution of Bayesian probability from a theoretical concept to a critical wartime intelligence tool.'}\n",
      "\u001B[0m\u001B[1;3;34mObservation: The evolution of Bayesian probability began with its theoretical foundations laid by Thomas Bayes in the 18th century, where it was initially viewed as a method for updating beliefs based on new evidence. Bayes' rule, which allows for the incorporation of prior knowledge into statistical inference, faced significant skepticism and was largely ignored by the academic community for many years.\n",
      "\n",
      "In the 19th century, Pierre Simon Laplace further developed the concept, applying it to various scientific problems and establishing a more formal mathematical framework. Despite his contributions, Bayesian methods remained controversial, often overshadowed by frequentist approaches that emphasized objective data and repeatable experiments.\n",
      "\n",
      "The turning point for Bayesian probability came during the Second World War, when its practical applications were recognized in military intelligence. Mathematicians and cryptanalysts, including Alan Turing and his colleagues at Bletchley Park, utilized Bayesian methods to break complex codes, such as the German Enigma. Turing's work involved developing a Bayesian scoring system to assess the likelihood of various hypotheses based on intercepted messages, which proved crucial in deciphering enemy communications.\n",
      "\n",
      "After the war, Bayesian methods began to gain traction in various fields, including medicine and business. Practitioners like Jerome Cornfield applied Bayesian techniques to identify causes of diseases, while Arthur Bailey and others in the insurance industry integrated Bayesian principles into their actuarial practices.\n",
      "\n",
      "By the mid-20th century, Bayesian probability had transitioned from a theoretical concept to a vital tool in decision-making under uncertainty, influencing areas such as military strategy, public health, and business analytics. The resurgence of interest in Bayesian methods during this period laid the groundwork for its acceptance and application in modern statistical analysis, leading to a broader recognition of its value in handling uncertainty and making informed decisions.\n",
      "\u001B[0m> Running step fdddb360-fb89-4e6d-aa69-33610581aa73. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: Bayesian probability evolved from a theoretical concept to a critical wartime intelligence tool through several key phases. Initially, it was introduced by Thomas Bayes in the 18th century as a method for updating beliefs based on new evidence, but it faced skepticism and was largely ignored. In the 19th century, Pierre Simon Laplace expanded on Bayes' work, applying it to scientific problems and establishing a mathematical framework, yet it remained overshadowed by frequentist approaches.\n",
      "\n",
      "The significant turning point occurred during World War II when Bayesian methods were recognized for their practical applications in military intelligence. Mathematicians like Alan Turing at Bletchley Park employed Bayesian techniques to break codes, including the German Enigma, by developing a scoring system to evaluate hypotheses based on intercepted messages.\n",
      "\n",
      "Post-war, Bayesian methods gained traction in various fields, including medicine and business, as practitioners began to apply these techniques to real-world problems. By the mid-20th century, Bayesian probability had become a vital tool for decision-making under uncertainty, influencing military strategy, public health, and business analytics. This resurgence laid the groundwork for its acceptance in modern statistical analysis, highlighting its value in managing uncertainty and making informed decisions.\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:53:25.481615Z",
     "start_time": "2024-12-10T04:51:47.205961Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b8c5afe961629143",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[58], line 13\u001B[0m\n\u001B[1;32m     10\u001B[0m       \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSource: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msource[:\u001B[38;5;241m30\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     11\u001B[0m       \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPage: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 13\u001B[0m \u001B[43mGetSources\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[58], line 10\u001B[0m, in \u001B[0;36mGetSources\u001B[0;34m(response)\u001B[0m\n\u001B[1;32m      7\u001B[0m source \u001B[38;5;241m=\u001B[39m text_node\u001B[38;5;241m.\u001B[39mmetadata\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfile_name\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m# Access metadata using .metadata.get()\u001B[39;00m\n\u001B[1;32m      8\u001B[0m page \u001B[38;5;241m=\u001B[39m text_node\u001B[38;5;241m.\u001B[39mmetadata\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpage_label\u001B[39m\u001B[38;5;124m'\u001B[39m)  \u001B[38;5;66;03m# Access metadata using .metadata.get()\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSource: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43msource\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPage: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:53:25.481702Z",
     "start_time": "2024-12-10T04:49:28.189173Z"
    }
   },
   "cell_type": "code",
   "source": "print(response.source_nodes.metadata)",
   "id": "e05544df6632675a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NodeWithScore(node=TextNode(id_='945126b6-7c8e-4322-ac1c-e03b7025ec8d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Bayesian probability originated as a theoretical framework aimed at updating beliefs based on new evidence. This iterative process involves three key components: Prior (the initial belief), Likelihood (the probability of observing the data given the belief), and Posterior (the updated belief after considering the new data). This method allows for continuous refinement of understanding as more information becomes available.\\n\\nOver time, Bayesian methods transitioned from purely theoretical applications to practical uses across various fields, notably in wartime intelligence. For example, the U.S. Army adopted Bayesian techniques for testing weapons systems, particularly in scenarios where large sample sizes were not feasible. This approach enabled analysts to merge test data with insights from similar systems and previous tests, thereby improving decision-making in uncertain environments.\\n\\nAdditionally, Bayesian techniques have been utilized in assessing terrorist threats, where they integrate expert opinions and historical data to forecast potential risks. This adaptability underscores the significance of Bayesian methods in real-world applications, particularly in military and security contexts. Overall, the evolution of Bayesian probability illustrates its transformation from a mathematical concept into a crucial analytical tool for navigating complex and uncertain situations.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6953857723509816)]\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:53:25.481786Z",
     "start_time": "2024-12-10T02:07:54.838673Z"
    }
   },
   "cell_type": "code",
   "source": "print(response)",
   "id": "cf4ba5e0a738435",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian probability began as a theoretical framework focused on the iterative process of updating beliefs based on new information. This involved the concepts of Prior, Likelihood, and Posterior, which together allow for the continuous recalibration of beliefs as new data is introduced.\n",
      "\n",
      "Over time, this theoretical foundation found practical applications, particularly in military contexts. The U.S. Army recognized the limitations of traditional frequentist methods, especially when dealing with large sample sizes, and adopted Bayesian techniques for testing weapons systems like the Stryker vehicles. These methods enabled the integration of test data with prior information and data from similar systems, proving effective in complex and dynamic environments.\n",
      "\n",
      "Furthermore, Bayesian approaches have been instrumental in assessing terrorist threats. By combining expert opinions with historical data, these techniques facilitate the evaluation of potential risks, showcasing their adaptability and relevance in security contexts.\n",
      "\n",
      "This evolution highlights how Bayesian probability transitioned from a purely theoretical concept to a vital tool in wartime intelligence, reflecting its growing importance in managing uncertainty across various fields, including military strategy and modern technology.\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:53:25.481888Z",
     "start_time": "2024-12-10T02:22:14.349042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# üßë‚Äçüíº Local Librarian AI Chatbot\")\n",
    "\n",
    "    # File upload section\n",
    "    with gr.Tab(\"File Upload\"):\n",
    "        gr.Markdown(\"## Upload Your Files to the System\")\n",
    "        file_upload = gr.File(label=\"Upload Documents\", file_count=\"multiple\", type=\"filepath\")\n",
    "        file_output = gr.Markdown(label=\"Uploaded Files\")\n",
    "        file_upload.upload(fn=handle_file_upload, inputs=file_upload, outputs=file_output)\n",
    "\n",
    "    # Chat and search interface\n",
    "    with gr.Tab(\"Search & Query\"):\n",
    "        gr.Markdown(\"## Ask the Librarian Anything\")\n",
    "\n",
    "        # Input fields for query and conversation history\n",
    "        query_input = gr.Textbox(label=\"Search Query\", placeholder=\"Enter your search query here...\")\n",
    "        search_button = gr.Button(\"Search\")\n",
    "        conversation_history = gr.Textbox(label=\"Conversation History\", interactive=False, lines=10)\n",
    "        source_display = gr.Textbox(label=\"Source Citations\", interactive=False, lines=5)\n",
    "\n",
    "        # Show example prompts\n",
    "        prompt_examples = gr.Button(\"Show Prompt Examples\")\n",
    "        examples_output = gr.Markdown()\n",
    "\n",
    "        search_button.click(fn=search_query,\n",
    "                            inputs=[query_input, conversation_history, source_display, examples_output],\n",
    "                            outputs=[conversation_history, source_display])\n",
    "        prompt_examples.click(fn=show_prompt_examples, outputs=examples_output)\n",
    "\n",
    "    # Instructions\n",
    "    gr.Markdown(\"### How to use this app:\")\n",
    "    gr.Markdown(\"\"\"\n",
    "        1. In the 'File Upload' tab, upload your documents to make them available for search.\n",
    "        2. In the 'Search & Query' tab, input your query in the 'Search Query' field.\n",
    "        3. Press the 'Search' button to see the results and the source citations.\n",
    "        4. You can review the conversation history as it evolves.\n",
    "        5. Use the 'Show Prompt Examples' button to see some predefined prompts to guide you.\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Accordion(\"About this demo\"):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            This demo showcases several Gradio components for a local librarian AI chatbot:\n",
    "            - File upload functionality to import documents.\n",
    "            - Search functionality with conversation history and source citation.\n",
    "            - Premade prompt examples to help users get started.\n",
    "            - Simple Markdown and interactive components for a user-friendly experience.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "demo.launch()\n"
   ],
   "id": "e9b7cd4dc80c85a5",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'handle_file_upload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m     file_upload \u001B[38;5;241m=\u001B[39m gr\u001B[38;5;241m.\u001B[39mFile(label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUpload Documents\u001B[39m\u001B[38;5;124m\"\u001B[39m, file_count\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiple\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfilepath\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      9\u001B[0m     file_output \u001B[38;5;241m=\u001B[39m gr\u001B[38;5;241m.\u001B[39mMarkdown(label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUploaded Files\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m     file_upload\u001B[38;5;241m.\u001B[39mupload(fn\u001B[38;5;241m=\u001B[39m\u001B[43mhandle_file_upload\u001B[49m, inputs\u001B[38;5;241m=\u001B[39mfile_upload, outputs\u001B[38;5;241m=\u001B[39mfile_output)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Chat and search interface\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m gr\u001B[38;5;241m.\u001B[39mTab(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSearch & Query\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "\u001B[0;31mNameError\u001B[0m: name 'handle_file_upload' is not defined"
     ]
    }
   ],
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
